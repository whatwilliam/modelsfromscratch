{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import * #this is where Conv2D, MaxPool2D,Flatten,Dense come from -- read the tf documentations to figure out how to customize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_val,y_val) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 17:45:09.880010 140175419647744 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,473,610\n",
      "Trainable params: 2,473,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([]) #sequential means that model layers are added in the order you .add them\n",
    "\n",
    "#Convolutions takes inputs: filters, kernel_size, input_shape, strides, padding, activation but we will define all of these so you can see parameters\n",
    "model.add(tf.keras.layers.Conv2D(filters=64,\n",
    "                                kernel_size=(3,3),\n",
    "                                padding='same', \n",
    "                                strides=1,\n",
    "                                activation='relu',\n",
    "                                input_shape=(32,32,3)))\n",
    "\n",
    "#maxpooling generally used to downsample(reduce dimensions of) the image in this case: 32x32x3 to 16x16x3\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),padding='same',strides=None))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters = 128,\n",
    "                                 kernel_size=(3,3),\n",
    "                                 padding='same',\n",
    "                                 activation='relu' ))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(padding='same'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters = 256,\n",
    "                                 kernel_size=(3,3),\n",
    "                                 padding='same',\n",
    "                                 activation='relu' ))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(padding='same'))\n",
    "\n",
    "#Flatten transforms array to be 1D\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "#if you the read the paper for VGG, they call the last layer fully connected (FC), in tensorflow, dense is FC\n",
    "model.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10,activation='softmax')) #softmax is used to for the model to decide its answer\n",
    "\n",
    "model.summary() #layer by layer summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.0001), #optimizer determines learning rate, generally you want to start high and get lower as you fine tune\n",
    "              loss = 'sparse_categorical_crossentropy', #defining loss for the model; defines what the model considers the right or wrong answer\n",
    "               metrics=['accuracy']) #returns accuracy of the model while its training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 14s 284us/sample - loss: 2.2895 - acc: 0.4147 - val_loss: 1.3615 - val_acc: 0.5296\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 13s 256us/sample - loss: 1.1978 - acc: 0.5822 - val_loss: 1.2013 - val_acc: 0.5769\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 13s 257us/sample - loss: 1.0012 - acc: 0.6509 - val_loss: 1.0730 - val_acc: 0.6311\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 13s 255us/sample - loss: 0.8471 - acc: 0.7067 - val_loss: 1.0543 - val_acc: 0.6415\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 13s 258us/sample - loss: 0.7227 - acc: 0.7506 - val_loss: 0.9536 - val_acc: 0.6777\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 13s 256us/sample - loss: 0.6045 - acc: 0.7907 - val_loss: 0.9617 - val_acc: 0.6856\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 13s 258us/sample - loss: 0.5017 - acc: 0.8283 - val_loss: 0.9625 - val_acc: 0.6947\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 13s 262us/sample - loss: 0.3978 - acc: 0.8655 - val_loss: 1.0053 - val_acc: 0.6943\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 13s 258us/sample - loss: 0.3191 - acc: 0.8931 - val_loss: 0.9725 - val_acc: 0.7109\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 13s 260us/sample - loss: 0.2376 - acc: 0.9221 - val_loss: 1.0375 - val_acc: 0.7108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c8c37db38>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, #image and label data\n",
    "          batch_size = 64, #smaller batch sizes can ease GPU workload\n",
    "          epochs=10,\n",
    "          verbose=1, \n",
    "          validation_data=(x_val,y_val)) #validation image and label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
