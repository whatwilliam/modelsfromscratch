{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import sklearn.model_selection as sk\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import *\n",
    "# from keras.layers import Dropout\n",
    "# from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_val,y_val) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   2320        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 32)   9248        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 32)   9248        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 64)     18496       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 64)     256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 64)     36928       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 64)     256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 64)     36928       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 64)     256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 8, 64)     0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 64)     36928       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 64)     256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           650         global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 10)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 171,514\n",
      "Trainable params: 170,618\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#input layer for the start of your model -- needs to be the same size as your data \n",
    "#i.e. cifar's dimensions are 32 x 32 x 3\n",
    "\n",
    "inputs = Input(shape=(32,32,3))\n",
    "\n",
    "x = Conv2D(filters=16,kernel_size=3,padding='same',activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "for i in range(1):\n",
    "    x1 = Conv2D(filters=16,kernel_size=3,padding='same',activation='relu')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = Conv2D(filters=16,kernel_size=3,padding='same',activation='relu')(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x = Add()([x,x2])\n",
    "    x = Conv2D(filters=16,kernel_size=3,padding='same',activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "#downsampling the image to be 16 x 16 x 3\n",
    "x = Conv2D(filters=32,kernel_size=3,strides=2,padding='same',activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "for i in range(1):\n",
    "    x1 = Conv2D(filters=32,kernel_size=3,padding='same',activation='relu')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = Conv2D(filters=32,kernel_size=3,padding='same',activation='relu')(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x = Add()([x,x2])\n",
    "    x = Conv2D(filters=32,kernel_size=3,padding='same',activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "#downsampling the image to be 8 x 8 x 3    \n",
    "x = Conv2D(filters=64,kernel_size=3,strides=2,padding='same',activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "for i in range(1):\n",
    "    x1 = Conv2D(filters=64,kernel_size=3,padding='same',activation='relu')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = Conv2D(filters=64,kernel_size=3,padding='same',activation='relu')(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x = Add()([x,x2])\n",
    "    x = Conv2D(filters=64,kernel_size=3,padding='same',activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(10,activation='relu')(x)\n",
    "x = Softmax()(x)\n",
    "\n",
    "model = tf.keras.Model(inputs,x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.RMSPropOptimizer(learning_rate=0.001,momentum=0.9,decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 17:03:02.251165 140694756046592 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 48s 970us/sample - loss: 1.5469 - acc: 0.4374 - val_loss: 2.9386 - val_acc: 0.3464\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 43s 856us/sample - loss: 1.0693 - acc: 0.6328 - val_loss: 1.3932 - val_acc: 0.5973\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 43s 861us/sample - loss: 0.8957 - acc: 0.6992 - val_loss: 0.9557 - val_acc: 0.6786\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 43s 851us/sample - loss: 0.8105 - acc: 0.7335 - val_loss: 1.1931 - val_acc: 0.6523\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 43s 851us/sample - loss: 0.7499 - acc: 0.7567 - val_loss: 1.3047 - val_acc: 0.6291\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 43s 858us/sample - loss: 0.7076 - acc: 0.7753 - val_loss: 0.9886 - val_acc: 0.7310\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 43s 853us/sample - loss: 0.6753 - acc: 0.7870 - val_loss: 1.0308 - val_acc: 0.6999\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 43s 856us/sample - loss: 0.6426 - acc: 0.8011 - val_loss: 0.8047 - val_acc: 0.7666\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 43s 855us/sample - loss: 0.6144 - acc: 0.8113 - val_loss: 0.8149 - val_acc: 0.7554\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 42s 845us/sample - loss: 0.5868 - acc: 0.8198 - val_loss: 0.9602 - val_acc: 0.7422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff4e30c2ac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=10,verbose=1,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0804 17:11:40.639344 140694756046592 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "model.save('resnetmodel_1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 55s 1ms/sample - loss: 0.4236 - acc: 0.8678 - val_loss: 0.6328 - val_acc: 0.8240\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 49s 987us/sample - loss: 0.3709 - acc: 0.8848 - val_loss: 0.6493 - val_acc: 0.8237\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 50s 995us/sample - loss: 0.3518 - acc: 0.8918 - val_loss: 0.6605 - val_acc: 0.8252\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 50s 990us/sample - loss: 0.3449 - acc: 0.8945 - val_loss: 0.6707 - val_acc: 0.8276\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 51s 1ms/sample - loss: 0.3301 - acc: 0.9001 - val_loss: 0.7082 - val_acc: 0.8245\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 51s 1ms/sample - loss: 0.3131 - acc: 0.9056 - val_loss: 0.7045 - val_acc: 0.8263\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 49s 975us/sample - loss: 0.3089 - acc: 0.9072 - val_loss: 0.7123 - val_acc: 0.8293\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 49s 980us/sample - loss: 0.3006 - acc: 0.9100 - val_loss: 0.7463 - val_acc: 0.8268\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 49s 988us/sample - loss: 0.2907 - acc: 0.9133 - val_loss: 0.7530 - val_acc: 0.8251\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 49s 978us/sample - loss: 0.2807 - acc: 0.9160 - val_loss: 0.7907 - val_acc: 0.8213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff4beff1b00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = tf.train.RMSPropOptimizer(learning_rate=0.0001,momentum=0.9,decay=0.0001)\n",
    "model.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=10,verbose=1,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
