{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading datasets through tensorflow datasets\n",
    "#(x_train,y_train),(x_val,y_val) = cifar10.load_data() <-- this is the same thing but with the keras dataset\n",
    "#it's better to learn with tensorflow datasets because there are a lot more of them, so if you want to use datasets other than cifar or mnist they are pretty useful\n",
    "train_dataset = tfds.load(\"cifar10\", with_info=False,split=tfds.Split.TRAIN)\n",
    "#IMPORTANT: tfds.load returns a dataset as a dictionary, so .map must be used to iterate through data so model read and fit data\n",
    "train_dataset = train_dataset.map(lambda ele: tuple([ele['image'], ele['label']])).repeat().batch(16)\n",
    "\n",
    "test_dataset = tfds.load(\"cifar10\", with_info=False,split=tfds.Split.TEST)\n",
    "test_dataset = test_dataset.map(lambda ele: tuple([ele['image'], ele['label']])).repeat().batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are going to be turning the dense block into a function so the model looks cleaner\n",
    "#also because we use the same series of convolutions over and over\n",
    "#you'll notice dense block is smaller and more modular than in the original paper. This is because cifar10 doesn't need as much processing \n",
    "def dense_block(inputs):\n",
    "    x1 = Conv2D(filters=16,kernel_size=1,padding='same',activation='relu')(inputs)\n",
    "    x1 = Conv2D(filters=32,kernel_size=3,padding='same',activation='relu')(x1)\n",
    "    \n",
    "    x2 = Conv2D(filters=16,kernel_size=1,padding='same',activation='relu')(x1)\n",
    "    x2 = Conv2D(filters=32,kernel_size=3,padding='same',activation='relu')(x2)\n",
    "    \n",
    "    #combine x1 and x2 channels\n",
    "    x2 = Concatenate()([x1,x2])\n",
    "    \n",
    "    x3 = Conv2D(filters=16,kernel_size=1,padding='same',activation='relu')(x2)\n",
    "    x3 = Conv2D(filters=32,kernel_size=3,padding='same',activation='relu')(x3)\n",
    "    \n",
    "    #combine x1, x2, and x3 channels\n",
    "    concat = Concatenate()([x1,x2,x3])\n",
    "    \n",
    "    x4 = Conv2D(filters=16,kernel_size=1,padding='same',activation='relu')(concat)\n",
    "    x4 = Conv2D(filters=32,kernel_size=3,padding='same',activation='relu')(x4)\n",
    "    \n",
    "    #combine x1, x2, x3, and x4 channels\n",
    "    concat = Concatenate()([x1,x2,x3,x4])\n",
    "    \n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   2320        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 16)   2320        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 8, 8, 16)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 16)     272         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 32)     4640        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 16)     528         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 32)     4640        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 64)     0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 16)     1040        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 32)     4640        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 128)    0           conv2d_4[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 16)     2064        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 32)     4640        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 160)    0           conv2d_4[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 16)     2576        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 16)     64          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 4, 4, 16)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 16)     272         average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 4, 4, 32)     4640        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 16)     528         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 32)     4640        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4, 4, 64)     0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 16)     1040        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 32)     4640        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4, 4, 128)    0           conv2d_13[0][0]                  \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 16)     2064        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 32)     4640        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 4, 4, 160)    0           conv2d_13[0][0]                  \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 16)     2576        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 16)     64          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 2, 2, 16)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 2, 2, 16)     272         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 2, 2, 32)     4640        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 2, 2, 16)     528         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 2, 2, 32)     4640        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 2, 2, 64)     0           conv2d_22[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 2, 2, 16)     1040        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 2, 2, 32)     4640        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 2, 2, 128)    0           conv2d_22[0][0]                  \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 2, 2, 16)     2064        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 2, 2, 32)     4640        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 2, 2, 160)    0           conv2d_22[0][0]                  \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 160)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           1610        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 10)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 79,562\n",
      "Trainable params: 79,402\n",
      "Non-trainable params: 160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(32,32,3)) #cifar images are 32x32 color images\n",
    "x = Conv2D(filters=16,kernel_size=3,padding='same',activation='relu')(inputs)\n",
    "x = BatchNormalization()(x) #having batch norms after convolutions can help model converge\n",
    "x = Conv2D(filters=16,kernel_size=3,padding='same',activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=16,kernel_size=3,strides=2,padding='same',activation='relu')(x) #downsampling to 16x16\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=3,strides=2,padding='same')(x) #downsampling again to 8x8\n",
    "\n",
    "x = dense_block(x)\n",
    "\n",
    "x = Conv2D(filters=16,kernel_size=1,padding='same',activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = AveragePooling2D(pool_size=2,strides=2,padding='same')(x) #downsampling to 4x4\n",
    "\n",
    "x = dense_block(x)\n",
    "    \n",
    "x = Conv2D(filters=16,kernel_size=1,padding='same',activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = AveragePooling2D(pool_size=2,strides=2,padding='same')(x) #downsampling to 2x2\n",
    "\n",
    "x = dense_block(x) \n",
    "\n",
    "x = GlobalAveragePooling2D()(x) #similar function to Flatten() but removes location based bias\n",
    "x = Dense(10,activation='relu')(x) #fully connect all 10 classes\n",
    "x = Softmax()(x)\n",
    "\n",
    "model = tf.keras.Model(inputs,x)\n",
    "#output layers and parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0811 15:38:02.055115 139751290283776 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20900/50000 [===========>..................] - ETA: 13:45 - loss: 1.6630 - acc: 0.4229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0811 15:47:55.148799 139751290283776 ultratb.py:155] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-2ce3bcf35918>\", line 3, in <module>\n",
      "    model.fit(train_dataset,steps_per_epoch=50000,epochs=10,verbose=1,validation_data=test_dataset,validation_steps=10000)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\", line 694, in fit\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\", line 1433, in fit_generator\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py\", line 264, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\", line 1175, in train_on_batch\n",
      "    outputs = self.train_function(ins)  # pylint: disable=not-callable\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\", line 3443, in __call__\n",
      "    outputs = self._graph_fn(*converted_inputs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\", line 561, in __call__\n",
      "    return self._call_flat(args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\", line 660, in _call_flat\n",
      "    outputs = self._inference_function.call(ctx, args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\", line 434, in call\n",
      "    ctx=ctx)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1454, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1411, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 671, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 717, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.5/posixpath.py\", line 373, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.5/posixpath.py\", line 407, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/lib/python3.5/posixpath.py\", line 161, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "opt = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_dataset,steps_per_epoch=50000,epochs=10,verbose=1,validation_data=test_dataset,validation_steps=10000)\n",
    "#training takes quite a while, but you can see that the model is converging (loss decreases, accuracy increases)\n",
    "#with some fine-tuning, like reducing learning rate or adjusting hyperparameters, the model could be better, but for the sake of time we can use a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for quick results or comparisons you can install keras models trained on imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/keras-team/keras\n",
      "  Cloning https://github.com/keras-team/keras to /tmp/pip-xiFBOp-build\n",
      "Collecting git+https://github.com/keras-team/keras-applications\n",
      "  Cloning https://github.com/keras-team/keras-applications to /tmp/pip-84fB6d-build\n",
      "Collecting numpy>=1.9.1 (from Keras==2.2.4)\n",
      "  Using cached https://files.pythonhosted.org/packages/1f/c7/198496417c9c2f6226616cff7dedf2115a4f4d0276613bab842ec8ac1e23/numpy-1.16.4-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting scipy>=0.14 (from Keras==2.2.4)\n",
      "  Using cached https://files.pythonhosted.org/packages/1d/f6/7c16d60aeb3694e5611976cb4f1eaf1c6b7f1e7c55771d691013405a02ea/scipy-1.2.2-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting six>=1.9.0 (from Keras==2.2.4)\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting pyyaml (from Keras==2.2.4)\n",
      "Collecting h5py (from Keras==2.2.4)\n",
      "  Using cached https://files.pythonhosted.org/packages/53/08/27e4e9a369321862ffdce80ff1770553e9daec65d98befb2e14e7478b698/h5py-2.9.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting keras_applications>=1.0.6 (from Keras==2.2.4)\n",
      "Collecting keras_preprocessing>=1.0.5 (from Keras==2.2.4)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Installing collected packages: numpy, scipy, six, pyyaml, h5py, keras-applications, keras-preprocessing, Keras\n",
      "  Running setup.py install for Keras ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed Keras-2.2.4 h5py-2.9.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 numpy-1.16.4 pyyaml-5.1.2 scipy-1.2.2 six-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/keras-team/keras git+https://github.com/keras-team/keras-applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121 #121 layer densenet made by keras through tensorflow lib\n",
    "import tensorflow.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "densenet121 (Model)          (None, 1000)              8062504   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10010     \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 8,072,514\n",
      "Trainable params: 10,010\n",
      "Non-trainable params: 8,062,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(32,32,3)) #original cifar data size\n",
    "x = tf.keras.layers.UpSampling2D(size=7)(inputs) #imagenet uses 224x224 size, so to match pretrained downsampling, 32x32 needs to be upsampled by 7 to get a 224x224 image\n",
    "densenet = tf.keras.applications.DenseNet121(include_top=True,\n",
    "                                      weights='imagenet',\n",
    "                                      classes=1000) #introducing pretrained model\n",
    "for layer in densenet.layers:\n",
    "    layer.trainable = False #freezing weights, so pretrained weights aren't affected by training\n",
    "    \n",
    "x = densenet(x)\n",
    "x = tf.keras.layers.Dense(10, activation='relu')(x) #divide answer into 10 possible classes\n",
    "x = Softmax()(x)\n",
    "\n",
    "model = tf.keras.Model(inputs,x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8196s 164ms/step - loss: 2.0766 - acc: 0.5253 - val_loss: 2.3343 - val_acc: 0.1146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f191e4414e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_dataset,steps_per_epoch=50000,epochs=1,verbose=1,validation_data=test_dataset,validation_steps=10000) #training the top layers for these answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(train_dataset)) #iterating dataset into image and label (like x_train and y_train)\n",
    "image_val,label_val = next(iter(test_dataset)) #iterating dataset into image and label (like x_test and y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next we will see how well the model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape (16, 32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f191c8d9c50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt #this is how we display images\n",
    "%matplotlib inline\n",
    "\n",
    "print('Test data shape', image.shape)\n",
    "_,(ax1,ax2) = plt.subplots(1,2)\n",
    "ax1.imshow(image[0]) #example 1\n",
    "ax2.imshow(image[7]) #example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=915613, shape=(), dtype=int64, numpy=9>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_val[0] #actual correct answer to check how well model is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___number key____\n",
    "# airplane: 0\n",
    "# automobile: 1\n",
    "# bird: 2\n",
    "# cat: 3\n",
    "# deer: 4\n",
    "# dog: 5\n",
    "# frog: 6\n",
    "# horse: 7\n",
    "# ship: 8\n",
    "# truck: 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
